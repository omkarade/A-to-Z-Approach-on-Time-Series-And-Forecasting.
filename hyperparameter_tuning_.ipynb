{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarade/A-to-Z-Approach-on-Time-Series-And-Forecasting./blob/main/hyperparameter_tuning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c store-sales-time-series-forecasting\n",
        "! unzip store-sales-time-series-forecasting.zip"
      ],
      "metadata": {
        "id": "MVfshptSrRvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pylab \n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score \n",
        "import pylab \n",
        "from math import sqrt\n",
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "n98KYl_UrR3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tran=pd.read_csv('train.csv')\n",
        "stores=pd.read_csv('stores.csv')\n",
        "transactions=pd.read_csv('transactions.csv')\n",
        "oil=pd.read_csv('oil.csv')\n",
        "holidays_events=pd.read_csv('holidays_events.csv')\n",
        "data1 = tran.merge(stores, how = 'left', on = 'store_nbr' )\n",
        "data1['date'] = pd.to_datetime(data1['date'])\n",
        "holidays_events['date'] = pd.to_datetime(holidays_events['date'])\n",
        "oil['date'] = pd.to_datetime(oil['date'])\n",
        "data2 = data1.merge(holidays_events, how = 'left', on = 'date' )\n",
        "data2 = data2.merge(oil, how ='left', on ='date')\n",
        "data2[\"type_y\"] = data2[\"type_y\"].fillna(\"Not Holiday\")\n",
        "data2[\"locale\"] = data2[\"locale\"].fillna(\"Not Holiday\")\n",
        "data2[\"locale_name\"] = data2[\"locale_name\"].fillna(\"Ecuador\")\n",
        "data2[\"description\"] = data2[\"description\"].fillna(\"NA\")\n",
        "data2[\"transferred\"] = data2[\"transferred\"].fillna(False)\n",
        "data2[\"dcoilwtico\"] = data2[\"dcoilwtico\"].fillna(np.mean(data2[\"dcoilwtico\"]))\n",
        "data2[\"description\"] = data2[\"description\"].fillna(\"NA\")\n",
        "data2[\"month\"] = data2['date'].map(lambda x: x.month)"
      ],
      "metadata": {
        "id": "96NmrJtLrR85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2=data2.drop(columns=\"dcoilwtico\")\n",
        "data2=data2.drop(columns=\"id\")\n",
        "data2=data2.drop(columns=\"transferred\")"
      ],
      "metadata": {
        "id": "PaALJRwDrSB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=data2[:28000]\n",
        "trainn=train[:22000]\n",
        "testn=train[22000:]"
      ],
      "metadata": {
        "id": "xWq_CwB6rtXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clen_to_pred(data2,fulldata,model=\"hyperparameter_tuning\"):\n",
        "#training RandomForestRegressor Model\n",
        "  if model==\"hyperparameter_tuning\":\n",
        "    descp=pd.concat([data2,fulldata], ignore_index=True, axis=0)\n",
        "    descp=descp.drop(columns=\"date\")\n",
        "    catage=descp[[\"family\",\"city\",\"state\",\"type_x\",\"type_y\",\"locale\",\"locale_name\",\"description\"]]\n",
        "    #Converting Categorical Features Into One Hot Encoding  \n",
        "    descr=pd.get_dummies(catage)\n",
        "    descr[\"store_nbr\"]=descp[\"store_nbr\"]\n",
        "    descr[\"onpromotion\"]=descp[\"onpromotion\"]\n",
        "    descr[\"cluster\"]=descp[\"cluster\"]\n",
        "\n",
        "    #Adding lag Features\n",
        "    train=descr[:22000]\n",
        "    train[\"sales\"]=fulldata[\"sales\"]\n",
        "    train['sales_lag_15'] = train['sales'].shift(2)\n",
        "    train['sales_lag_30'] = train['sales'].shift(3)\n",
        "    train['sales_lag_60'] = train['sales'].shift(7)\n",
        "    train['sales_lag_140'] = train['sales'].shift(15)\n",
        "    train['sales_lag_15'] = train['sales_lag_15'].fillna(0)\n",
        "    train['sales_lag_30'] = train['sales_lag_30'].fillna(0)\n",
        "    train['sales_lag_60'] = train['sales_lag_60'].fillna(0)\n",
        "    train['sales_lag_140'] = train['sales_lag_140'].fillna(0)\n",
        "    train['Expo_moving_sale_2']=train['sales'].ewm(com=0.2).mean()\n",
        "    train['Expo_moving_sale_4']=train['sales'].ewm(com=0.4).mean()\n",
        "    train['Expo_moving_sale_6']=train['sales'].ewm(com=0.6).mean()\n",
        "    train['Expo_moving_sale_8']=train['sales'].ewm(com=0.8).mean()\n",
        "    \n",
        "    #train=train.drop(columns=\"sales\")\n",
        "    y_main=fulldata.sales\n",
        "    train=train.drop(columns=\"sales\")\n",
        "    train=train.fillna(0)\n",
        "    train1=train[:22000]\n",
        "  return train1,y_main"
      ],
      "metadata": {
        "id": "ycEzrKPvrtcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=data2[:28000]\n",
        "trainn=train[:22000]\n",
        "testn=train[22000:]\n",
        "df_featl,df_targetl=clen_to_pred(testn,trainn)"
      ],
      "metadata": {
        "id": "CDfyTdRCrtgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "  \n",
        "X_train, X_test, y_train, y_test = train_test_split(df_featl, np.ravel(df_targetl),test_size = 0.30, random_state = 101)\n"
      ],
      "metadata": {
        "id": "47Y51Nf9sCoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hyperparameter_tuning :-svm**"
      ],
      "metadata": {
        "id": "qKOMTzpzxx7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "\n",
        "n_samples, n_features = 10, 5\n",
        "np.random.seed(0)\n",
        "y = np.random.randn(n_samples)\n",
        "X = np.random.randn(n_samples, n_features)\n",
        "parameters = {'kernel': ('rbf','poly'), 'C':[1.5, 10],'gamma': [1e-7],'epsilon':[0.1,0.5]}\n",
        "svr = svm.SVR()\n",
        "clf = GridSearchCV(svr, parameters)\n",
        "clf.fit(X_train,y_train)\n",
        "clf.best_params_\n"
      ],
      "metadata": {
        "id": "QUjmrzdwsCre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd220c7-932e-4d81-f1ca-659fb2a6802e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10, 'epsilon': 0.5, 'gamma': 1e-07, 'kernel': 'rbf'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hyperparameter_tuning :- DecisionTreeRegressor**"
      ],
      "metadata": {
        "id": "QMXnr1j8y-0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition, datasets\n",
        "from sklearn import tree\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "XxCwzf3esCvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for max_d in range(1,15):\n",
        "  model = DecisionTreeRegressor(max_depth=max_d, random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "  print('The Training Accuracy for max_depth {} is:'.format(max_d), model.score(X_train, y_train))\n",
        "  print('')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBfN-Hy0fI67",
        "outputId": "d361ff20-4279-4fb7-d2c8-ca56b03737e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Training Accuracy for max_depth 1 is: 0.6340521095132865\n",
            "\n",
            "The Training Accuracy for max_depth 2 is: 0.878538025026294\n",
            "\n",
            "The Training Accuracy for max_depth 3 is: 0.9577874304555287\n",
            "\n",
            "The Training Accuracy for max_depth 4 is: 0.9791129899294101\n",
            "\n",
            "The Training Accuracy for max_depth 5 is: 0.9900729418500652\n",
            "\n",
            "The Training Accuracy for max_depth 6 is: 0.9958118296899233\n",
            "\n",
            "The Training Accuracy for max_depth 7 is: 0.9980045516596512\n",
            "\n",
            "The Training Accuracy for max_depth 8 is: 0.9990677491779041\n",
            "\n",
            "The Training Accuracy for max_depth 9 is: 0.9994683547905004\n",
            "\n",
            "The Training Accuracy for max_depth 10 is: 0.9997197405380636\n",
            "\n",
            "The Training Accuracy for max_depth 11 is: 0.9998536251208784\n",
            "\n",
            "The Training Accuracy for max_depth 12 is: 0.9999204492504445\n",
            "\n",
            "The Training Accuracy for max_depth 13 is: 0.9999558545865729\n",
            "\n",
            "The Training Accuracy for max_depth 14 is: 0.9999774278102842\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**hyperparameter_tuning :- RandomForestRegressor**"
      ],
      "metadata": {
        "id": "AsZ1OBrVzpXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RFReg = RandomForestRegressor(n_estimators = 500, random_state = 1, n_jobs = -1) \n",
        "\n",
        "param_grid = { \n",
        "    'max_features' : [\"sqrt\", \"log2\"],\n",
        "    'min_samples_split' : np.linspace(0.1, 1.0, 10),\n",
        "     'max_depth' : [x for x in range(1,8)]\n",
        "\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "CV_rfc = GridSearchCV(estimator=RFReg, param_grid=param_grid, cv= 10, n_jobs = -1)\n",
        "CV_rfc.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "1qk7LolfzLD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87420614-09f3-4927-847b-1784760b603b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10,\n",
              "             estimator=RandomForestRegressor(n_estimators=500, n_jobs=-1,\n",
              "                                             random_state=1),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7],\n",
              "                         'max_features': ['sqrt', 'log2'],\n",
              "                         'min_samples_split': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CV_rfc.best_params_\n"
      ],
      "metadata": {
        "id": "5DZ_bI8czLGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa9e76f-4603-4dbd-bac9-57df27e6e0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7, 'max_features': 'sqrt', 'min_samples_split': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rFHRAp6uzLec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}